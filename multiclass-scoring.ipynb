{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "046cafc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import stumpy\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import random\n",
    "import math\n",
    "import pickle\n",
    "from statistics import mean\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cadcd734",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../nonzero_traces.npy', 'rb') as f:\n",
    "    traces = pickle.load(f)\n",
    "    \n",
    "with open('../shapelets.pkl', 'rb') as f:\n",
    "    shapelets = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dcd23c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nbuild an average \"representative trace\" from a collection\\n5 shapelets of A vs B,C\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Compute the minimum distance beteen data samples and shapelets\n",
    "Input:\n",
    "    data = list of individual packet traces\n",
    "    shapelets = list of shapelets\n",
    "Output:\n",
    "    minimum distance between each sample in data compared with each sample in shapelet\n",
    "    shape = (len(data),len(shapelets))\n",
    "'''\n",
    "def distance_to_shapelet(data, shapelets):\n",
    "    #data = np.asarray(data)\n",
    "    #print(len(data))\n",
    "    \n",
    "    # processed output data\n",
    "    data_out = np.zeros((len(data),len(shapelets)))\n",
    "    \n",
    "    # loop over each sample in the dataset\n",
    "    for i,sample in enumerate(tqdm(data)):\n",
    "        shapelet_score = np.empty(len(shapelets))\n",
    "        # for each shapelet, calculate distance and assign a score\n",
    "        for j,shapelet in enumerate(shapelets):\n",
    "            dist = stumpy.mass(shapelet, sample)\n",
    "            shapelet_score[j] = dist.min()\n",
    "        data_out[i] = shapelet_score\n",
    "    \n",
    "    return data_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d95ac829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-processing done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d27103fbda304bac8df43abbfa32b494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/388486 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(388486, 100)\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "shapelet_length = 400\n",
    "\n",
    "# get X values for input\n",
    "\n",
    "X, y = [], []\n",
    "\n",
    "for i in range(450000):\n",
    "    random_id = random.randrange(100)\n",
    "    random_trace = random.choice(traces[random_id])\n",
    "    X.append([random_trace])\n",
    "    y.append(random_id)\n",
    "\n",
    "# process and remove useless entries (too short)\n",
    "X = [np.asarray(trace).astype('float64') for trace in X]\n",
    "X = [trace[~np.isnan(trace)] for trace in X]    \n",
    "removals = [i for i,x in enumerate(X) if len(x) < shapelet_length]\n",
    "for idx in removals:\n",
    "    X[idx] = None\n",
    "    y[idx] = None\n",
    "X = [trace for trace in X if trace is not None]\n",
    "y = [value for value in y if value is not None]\n",
    "\n",
    "print(\"pre-processing done\")\n",
    "\n",
    "# compute distance between input trace and shapelet arrays\n",
    "# return as new X\n",
    "\n",
    "X = distance_to_shapelet(X, shapelets)\n",
    "\n",
    "print(X.shape)\n",
    "print(X[0].shape)\n",
    "\n",
    "with open('../X.pkl', 'wb') as f:\n",
    "    pickle.dump(X, f)\n",
    "\n",
    "with open('../y.pkl', 'wb') as f:\n",
    "    pickle.dump(y, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68b3426",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../X.pkl', 'rb') as f:\n",
    "    X = pickle.load(f)\n",
    "\n",
    "with open('../y.pkl', 'rb') as f:\n",
    "    y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "115117c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed: 13.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(verbose=1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "#print(\"Training and testing samples collected ...\")\n",
    "\n",
    "clf = RandomForestClassifier(verbose=1)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e337ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    2.2s finished\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "y_prob = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "557a6b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38849\n",
      "0.80617261705578\n"
     ]
    }
   ],
   "source": [
    "print(len(y_prob))\n",
    "\n",
    "correct = 0\n",
    "\n",
    "for i in range(len(y_prob)):\n",
    "    k = 1\n",
    "    ind = np.argpartition(y_prob[i], -k)[-k:]\n",
    "    if y_test[i] in ind:\n",
    "        correct += 1\n",
    "\n",
    "print(correct/len(y_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82a64f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Parameters\n",
    "\n",
    "# Samples for shapelet extraction\n",
    "Shapelet size\n",
    "# Samples for classifier\n",
    "Hyper-parameters of classifier\n",
    "Traffic Representation\n",
    "\n",
    "Opt: concatenated shapelets\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
