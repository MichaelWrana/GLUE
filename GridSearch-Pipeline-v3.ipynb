{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1b6b6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import stumpy\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import pickle\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from statistics import mean\n",
    "from tqdm.auto import tqdm\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "198d8202",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Collects random samples from trace with id2 and computes the matrix profile of class1 compared with class 2\n",
    "\n",
    "Input: \n",
    "    trace1: packet traces from class 1\n",
    "    id2: id number for class 2 \n",
    "    num_traces: number of traces to select from class 2 (should be equal to class 1)\n",
    "    shapelet_size: length of shapelets\n",
    "    \n",
    "Output:\n",
    "    Matrix profile of trace1 compared with trace2\n",
    "'''\n",
    "def compare_profile(trace1, trace2, shapelet_size):\n",
    "    \n",
    "    length_diff = len(trace2) - len(trace1)\n",
    "    if(length_diff < 0):\n",
    "        trace2 = np.append(trace2, [np.nan] * abs(length_diff))\n",
    "        \n",
    "    #print(len(trace1))\n",
    "    #print(len(trace2))\n",
    "        \n",
    "    \n",
    "    c1_c2 = stumpy.stump(trace1, shapelet_size, trace2, ignore_trivial=False)[:, 0].astype(float)\n",
    "    c1_c2[c1_c2 == np.inf] = np.nan\n",
    "    \n",
    "    return c1_c2\n",
    "\n",
    "'''\n",
    "Compares a the matrix profile of a class trace with itself\n",
    "\n",
    "Input: \n",
    "    trace: packet traces from class 1\n",
    "    shapelet_size: length of shapelets\n",
    "    \n",
    "Output:\n",
    "    Matrix profile of trace compared with trace\n",
    "'''\n",
    "\n",
    "def same_profile(trace, shapelet_size):\n",
    "    \n",
    "    c1_c1 = stumpy.stump(trace, shapelet_size)[:, 0].astype(float)\n",
    "    c1_c1[c1_c1 == np.inf] = np.nan\n",
    "    \n",
    "    return c1_c1\n",
    "\n",
    "'''\n",
    "return indices of shapelet as one-hot encoded list\n",
    "'''\n",
    "def generate_shapelet(trace, diff, shapelet_size):\n",
    "    \n",
    "    idx = np.argmax(diff)\n",
    "    shapelet = np.asarray([1 if idx <= i < idx + shapelet_size else 0 for i in range(len(trace))])\n",
    "    \n",
    "    return shapelet\n",
    "\n",
    "'''\n",
    "Compute shapelet of greatest overlaps\n",
    "'''\n",
    "def find_overlap(trace_i, shapelets_i, shapelet_size):\n",
    "    #print(shapelets_i[0])\n",
    "    \n",
    "    merged_shapelets = np.sum(shapelets_i, axis=0)\n",
    "    \n",
    "    max_size = 0\n",
    "    start = 0\n",
    "    end = 0\n",
    "    \n",
    "    for i in range(0, len(merged_shapelets), shapelet_size):\n",
    "        current_size = np.sum(merged_shapelets[i:i+shapelet_size])\n",
    "        if current_size > max_size:\n",
    "            max_size = current_size\n",
    "            start = i\n",
    "            end = i + shapelet_size\n",
    "    \n",
    "    return trace_i[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41239be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Generates a set of 100 shapelets for each class in samples\n",
    "\n",
    "Input:\n",
    "    num_traces = Number of traces per class\n",
    "    shapelet_size = Size of shapelets\n",
    "    save: save results to file?\n",
    "    filename: if save, name & location of output file\n",
    "\n",
    "Output:\n",
    "    list object containing shapelets for each class\n",
    "\n",
    "'''\n",
    "def generate_shapelets(shapelet_coeff):\n",
    "    shapelet_storage = []\n",
    "    \n",
    "    # loop over all classes (generate shapelet for each class)\n",
    "    for i in tqdm(range(100)):\n",
    "        \n",
    "        # get the chosen sample from trace i\n",
    "        trace_i = chosen_traces[i].astype('float64')\n",
    "        shapelet_size = math.floor(shapelet_coeff * len(trace_i))\n",
    "        \n",
    "        shapelets_i = np.zeros((100, len(trace_i)))\n",
    "        #print(shapelets_i.shape)\n",
    "        \n",
    "        # generate profile of i compared with itself\n",
    "        # length of sample is coeff* len*trace_i\n",
    "        ci_ci = same_profile(trace_i, shapelet_size)\n",
    "        \n",
    "        # loop over every other class and generate a profile for each one\n",
    "        for j in range(100):\n",
    "            # don't compare i with itself \n",
    "            if i == j:\n",
    "                continue\n",
    "            \n",
    "            trace_j = chosen_traces[j].astype('float64')\n",
    "            \n",
    "            # compute profile of i compared with j\n",
    "            ci_cj = compare_profile(trace_i, trace_j, shapelet_size)\n",
    "\n",
    "            # find largest value gap between other and i\n",
    "            diff_ci = ci_cj - ci_ci\n",
    "            \n",
    "            # generate best shapelet for i compared to j and store it in list\n",
    "            ci_shape = generate_shapelet(trace_i, diff_ci, shapelet_size)\n",
    "            shapelets_i[j] = ci_shape\n",
    "        \n",
    "        # compare shapelets between all classes and return the one which has the most overlap\n",
    "        # (i.e.) the shapelet that was chosen most between the 99 other classes\n",
    "        best_shapelet = find_overlap(trace_i, shapelets_i, shapelet_size)\n",
    "        # save to list\n",
    "        shapelet_storage.append(best_shapelet)\n",
    "    \n",
    "    return shapelet_storage   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "651bd8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Compute the minimum distance beteen data samples and shapelets\n",
    "Input:\n",
    "    data = list of individual packet traces\n",
    "    shapelets = list of shapelets\n",
    "Output:\n",
    "    minimum distance between each sample in data compared with each sample in shapelet\n",
    "    shape = (len(data),len(shapelets))\n",
    "'''\n",
    "def distance_to_shapelet(data, shapelets):\n",
    "    #data = np.asarray(data)\n",
    "    #print(len(data))\n",
    "    \n",
    "    # processed output data\n",
    "    data_out = np.zeros((len(data),len(shapelets)))\n",
    "    \n",
    "    # loop over each sample in the dataset\n",
    "    for i,sample in enumerate(tqdm(data)):\n",
    "        shapelet_score = np.empty(len(shapelets))\n",
    "        # for each shapelet, calculate distance and assign a score\n",
    "        for j,shapelet in enumerate(shapelets):\n",
    "            try:\n",
    "                dist = stumpy.mass(shapelet, sample)\n",
    "            except ValueError:\n",
    "                dist = stumpy.mass(sample, shapelet)\n",
    "            shapelet_score[j] = dist.min()\n",
    "        data_out[i] = shapelet_score\n",
    "    \n",
    "    return data_out\n",
    "\n",
    "'''\n",
    "Computes distances between input samples and shapelets, returns X for classifier\n",
    "Also cleans data and ensures no random errors due to length, NaN, etc...\n",
    "Underlying function that performs comparison is distance_to_shapelet\n",
    "Selects data samples (with replacement)\n",
    "note: some samples will always be bad so actual length of X is less\n",
    "\n",
    "Input:\n",
    "    num_traces = numner of traces to process\n",
    "    save = save output to file\n",
    "    filenames = tuple that represents (name of X file, name of y file)\n",
    "\n",
    "Output:\n",
    "    X values for classifier of shape (None, 100)\n",
    "    y values for classifier of shape (None, )\n",
    "'''\n",
    "\n",
    "def process_traces(num_traces, shapelets):\n",
    "    X, y = [], []\n",
    "\n",
    "    \n",
    "#     for i in range(num_traces):\n",
    "#         combo_trace = []\n",
    "#         combo_trace.append(random.choice(traces[random.randint(50,99)]))\n",
    "#         y_id = random.randint(0,49)\n",
    "#         combo_trace.append(random.choice(traces[y_id]))\n",
    "#         combo_trace.append(random.choice(traces[random.randint(50,99)]))\n",
    "#         out = np.concatenate((combo_trace[0],combo_trace[1],combo_trace[2]))\n",
    "        \n",
    "#         X.append(out)\n",
    "#         y.append(y_id)\n",
    "\n",
    "    # iterate over dictionary and re-format into X and y\n",
    "    for trace_id, trace_vals in traces.items():\n",
    "        for trace in trace_vals:\n",
    "            X.append(trace)\n",
    "            y.append(trace_id)\n",
    "    \n",
    "#     for i in range(num_traces):\n",
    "#         random_id = random.randrange(100)\n",
    "#         random_trace = random.choice(traces[random_id])\n",
    "#         X.append([random_trace])\n",
    "#         y.append(random_id)\n",
    "    \n",
    "    print(\"Size of X: \" + str(len(X)))\n",
    "    \n",
    "    \n",
    "    # convert traces into float64 data type\n",
    "    X = [np.asarray(trace).astype('float64') for trace in X]\n",
    "    \n",
    "    # clear empty trace values in data\n",
    "    X = [trace[~np.isnan(trace)] for trace in X]    \n",
    "\n",
    "    # compute distance between input trace and shapelet arrays\n",
    "    # return as new X\n",
    "\n",
    "    X = distance_to_shapelet(X, shapelets)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "485914fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Evaluate performance of sklearn classifier on data samples - 90/10 training testing split\n",
    "\n",
    "Input:\n",
    "    clf: sklearn classifier object\n",
    "    X: x values\n",
    "    y: y values\n",
    "    topk: k values for evaluation metrics\n",
    "Output:\n",
    "    list of length topk with accuracy for testing data\n",
    "'''\n",
    "\n",
    "def classifier_performance(clf, X, y, topk=[1,3,5]):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    y_prob = clf.predict_proba(X_test)\n",
    "    \n",
    "    scores = []\n",
    "    for k in topk:\n",
    "        correct = 0\n",
    "        for i in range(len(y_prob)):\n",
    "            ind = np.argpartition(y_prob[i], -k)[-k:]\n",
    "            if y_test[i] in ind:\n",
    "                correct += 1\n",
    "        scores.append(correct/len(y_prob))\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "146c66f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Utility function for pipeline of evaluating different grid search parameters\n",
    "Output: a new file located in ../results/param1-val1_param2-val2_param3-val3\n",
    "        the file contains a pickled python object\n",
    "        with the scores for top-1, top-3, and top-5 classifier accuracy\n",
    "'''\n",
    "# note: python multiprocessing is really annoying to work with\n",
    "# function needs to be in a separate .py file which is imported\n",
    "# and function can only have 1 argument\n",
    "# list input which is immediately used for what would be the arguments\n",
    "def evaluate_parameters(arr):\n",
    "    \n",
    "    num_experiment = arr[0]\n",
    "    shapelet_coeff = arr[1]\n",
    "    num_samples = 0\n",
    "    \n",
    "    filename = '../results/shapelets/' + 'num=' + str(num_experiment) + 'size=' + str(shapelet_coeff)\n",
    "    #filename = '../results/data/trace_choice'\n",
    "    with open(filename, 'rb') as f:\n",
    "        shapelets = pickle.load(f)\n",
    "    \n",
    "    shapelets = [shapelet.astype('float64') for shapelet in shapelets]\n",
    "    \n",
    "    X, y = process_traces(num_samples, shapelets)\n",
    "    \n",
    "    filename = '../results/data/X/' + 'num=' + str(num_experiment) + 'size=' + str(shapelet_coeff)\n",
    "    \n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(X, f)\n",
    "        \n",
    "    filename = '../results/data/y/' + 'num=' + str(num_experiment) + 'size=' + str(shapelet_coeff)\n",
    "    \n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(y, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae8b92b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP\n",
    "\n",
    "global traces\n",
    "\n",
    "with open('../ds19.npy', 'rb') as f:\n",
    "    traces = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e5bd4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0', '0']]\n"
     ]
    }
   ],
   "source": [
    "#nums = ['4.1', '4.2', '4.3']\n",
    "#size = ['0','1']\n",
    "#parameter_list = [[x,y] for x in nums for y in size]\n",
    "\n",
    "parameter_list = [['0','0']]\n",
    "\n",
    "print(parameter_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac00d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 1\n",
    "\n",
    "print(parameter_list)\n",
    "\n",
    "for parameters in parameter_list:\n",
    "    coeff = parameters[1]\n",
    "    shapelets = generate_shapelets(coeff)\n",
    "    \n",
    "    filename = '../results/shapelets/' + 'num=' + str(parameters[0]) + 'size=' + str(parameters[1])\n",
    "    \n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(shapelets, f)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c364ac3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of X: 10000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21ba5a68491844f1a9ab08f66456e673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_parameters(parameter_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0060f4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PART 2\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    from utils import evaluate_parameters\n",
    "    print(parameter_list)\n",
    "    \n",
    "    with Pool(6) as p:\n",
    "        p.map(evaluate_parameters, parameter_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ad0c0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num=3.0size=1\n",
      "num=3.1size=1\n",
      "num=3.2size=1\n",
      "(450000, 300)\n",
      "(450000,)\n"
     ]
    }
   ],
   "source": [
    "# merge X values from different datasets\n",
    "\n",
    "folder_X = \"../results/data/X/\"\n",
    "names = [\"num=3.0size=1\",\"num=3.1size=1\",\"num=3.2size=1\"]\n",
    "\n",
    "X = ()\n",
    "\n",
    "for filename in names: #os.listdir(folder_X): (for all files)\n",
    "    print(filename)\n",
    "    with open(folder_X + filename, 'rb') as f:\n",
    "        Xi = pickle.load(f)\n",
    "    X = X + (Xi,) \n",
    "        \n",
    "X = np.concatenate(X, axis=1)\n",
    "print(X.shape)\n",
    "\n",
    "with open(\"../results/data/y/num=2.0size=1\", 'rb') as f:\n",
    "    y = pickle.load(f)\n",
    "y = np.array(y) \n",
    "\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9301bbd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8040444444444445, 0.9175777777777778, 0.9481333333333334]\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "scores = classifier_performance(clf, X, y)\n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2addb05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "print(len(set(y_train)))\n",
    "print(len(set(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "057f54f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-15 08:08:52.703154: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-15 08:09:00.880816: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.losses import SparseCategoricalCrossentropy\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(1024),\n",
    "    Dense(512),\n",
    "    Dense(256),\n",
    "    Dense(128),\n",
    "    Dense(100)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0260a0f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to find data adapter that can handle input: <class 'numpy.ndarray'>, (<class 'list'> containing values of types {\"<class 'int'>\"})",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ww/7kn8t7y91gv3dzhg4tzjhq4m0000gn/T/ipykernel_29076/3108087705.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1081\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0madapter_cls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1082\u001b[0m         \u001b[0;31m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1083\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   1084\u001b[0m             \u001b[0;34m\"Failed to find data adapter that can handle \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m             \u001b[0;34m\"input: {}, {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_type_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_type_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to find data adapter that can handle input: <class 'numpy.ndarray'>, (<class 'list'> containing values of types {\"<class 'int'>\"})"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6b64985d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 2s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b0a0197b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45000, 100)\n",
      "(45000, 100)\n"
     ]
    }
   ],
   "source": [
    "print(predictions.shape)\n",
    "predictions = tf.nn.softmax(predictions)\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3057ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = 0\n",
    "for i, pred in enumerate(predictions):\n",
    "    final_pred = np.argmax(pred, 0)\n",
    "    \n",
    "    print(final_pred)\n",
    "    \n",
    "    if final_pred == y_test[i]:\n",
    "        score += 1\n",
    "\n",
    "print(score/len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "866a6d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0', '0']]\n",
      "[0.871, 0.95, 0.967]\n"
     ]
    }
   ],
   "source": [
    "## PART 3\n",
    "\n",
    "print(parameter_list)\n",
    "\n",
    "for parameters in parameter_list:\n",
    "    \n",
    "    filename = '../results/data/X/' + 'num=' + str(parameters[0]) + 'size=' + str(parameters[1])\n",
    "    \n",
    "    with open(filename, 'rb') as f:\n",
    "        X = pickle.load(f)\n",
    "    \n",
    "    filename = '../results/data/y/' + 'num=' + str(parameters[0]) + 'size=' + str(parameters[1])\n",
    "    \n",
    "    with open(filename, 'rb') as f:\n",
    "        y = pickle.load(f)\n",
    "    \n",
    "    clf = RandomForestClassifier()\n",
    "    scores = classifier_performance(clf, X, y)\n",
    "    \n",
    "    print(scores)\n",
    "    \n",
    "    outfile_name = \"../results/scores/\" + 'num=' + str(parameters[0]) + 'size=' + str(parameters[1])\n",
    "    \n",
    "    with open(outfile_name, 'wb') as f:\n",
    "        pickle.dump(scores, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5437fecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 4\n",
    "\n",
    "print(parameter_list)\n",
    "\n",
    "for parameters in parameter_list:\n",
    "    \n",
    "    filename = '../results/data/X/' + 'num=' + str(parameters[0]) + 'size=' + str(parameters[1])\n",
    "    \n",
    "    with open(filename, 'rb') as f:\n",
    "        X = pickle.load(f)\n",
    "        \n",
    "    filename = '../results/data/y/' + 'num=' + str(parameters[0]) + 'size=' + str(parameters[1])\n",
    "    \n",
    "    with open(filename, 'rb') as f:\n",
    "        y = pickle.load(f)\n",
    "    \n",
    "    clf = RandomForestClassifier()\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    matrix = confusion_matrix(y_test, y_pred)\n",
    "    scores = matrix.diagonal()/matrix.sum(axis=1)\n",
    "    \n",
    "    outfile_name = \"../results/scores_perclass/\" + 'num=' + str(parameters[0]) + 'size=' + str(parameters[1])\n",
    "    \n",
    "    with open(outfile_name, 'wb') as f:\n",
    "        pickle.dump(scores, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
