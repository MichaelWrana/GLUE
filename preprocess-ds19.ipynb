{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9a7f88ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "from modified_features import extract_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7227835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SECTION 1\n",
    "# process the data by converting DS-19 to our format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78cb9d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"../ds19/\"\n",
    "traces = {id: [None] * 100 for id in range(100)}\n",
    "indices = {id: 0 for id in range(100)}\n",
    "patterns = [re.compile(\"^\\d{2}-\\d{2}.cell\"), re.compile(\"^\\d{2}-\\d{1}.cell\"), re.compile(\"^\\d{1}-\\d{2}.cell\"), re.compile(\"^\\d{1}-\\d{1}.cell\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1b4fc111",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(filename, trace_id):\n",
    "    with open(data_folder + filename) as f:\n",
    "        raw_file = np.loadtxt(f)\n",
    "        \n",
    "    converted_file = np.asarray([row[0] * row[1] for row in raw_file])\n",
    "    \n",
    "    traces[trace_id][indices[trace_id]] = converted_file\n",
    "    indices[trace_id] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "444437d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(data_folder):\n",
    "    # 2-digit, 2-digit\n",
    "    if patterns[0].match(filename):\n",
    "        process(filename, int(filename[:2]))\n",
    "    # 2-digit, 1-digit\n",
    "    elif patterns[1].match(filename):\n",
    "        process(filename, int(filename[:2]))\n",
    "    # 1-digit, 2-digit or 1-digit, 1-digit\n",
    "    elif patterns[2].match(filename) or patterns[3].match(filename):\n",
    "        process(filename, int(filename[0]))\n",
    "\n",
    "with open('../ds19.npy', 'wb') as f:\n",
    "    pickle.dump(traces, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05da832f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SECTION 2\n",
    "# extract randomly selected shapelets from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "05c7b7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../datasets/ds19_ipt.npy\", 'rb') as f:\n",
    "    traces = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a3b3ff84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random shapelet selection\n",
    "\n",
    "for j in range(0, 6):\n",
    "\n",
    "    shapelets = [None] * 100\n",
    "\n",
    "    for i in range(100):\n",
    "        shapelets[i] = random.choice(traces[i])\n",
    "\n",
    "    with open('../results/shapelets/num=' + str(j), 'wb') as f:\n",
    "        pickle.dump(shapelets, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78671df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SECTION 3\n",
    "# process the data by extracting k-fp features from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d9db305c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"../ds19/\"\n",
    "traces = {id: [None] * 100 for id in range(100)}\n",
    "indices = {id: 0 for id in range(100)}\n",
    "patterns = [re.compile(\"^\\d{2}-\\d{2}.cell\"), re.compile(\"^\\d{2}-\\d{1}.cell\"), re.compile(\"^\\d{1}-\\d{2}.cell\"), re.compile(\"^\\d{1}-\\d{1}.cell\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9eb04c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_kfp(filename, trace_id):\n",
    "    \n",
    "    with open(data_folder + filename) as f:\n",
    "        # nightmare double list comprehension\n",
    "        # just loads the file where each line is a tuple (the whole file is stored as a list)\n",
    "        converted_file = [tuple([float(i) for i in line.rstrip().split('\\t')]) for line in f]\n",
    "    \n",
    "    traces[trace_id][indices[trace_id]] = converted_file\n",
    "    indices[trace_id] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a9b02657",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 20000/20000 [00:35<00:00, 556.85it/s]\n"
     ]
    }
   ],
   "source": [
    "for filename in tqdm(os.listdir(data_folder)):\n",
    "    # 2-digit, 2-digit\n",
    "    if patterns[0].match(filename):\n",
    "        process_kfp(filename, int(filename[:2]))\n",
    "    # 2-digit, 1-digit\n",
    "    elif patterns[1].match(filename):\n",
    "        process_kfp(filename, int(filename[:2]))\n",
    "    # 1-digit, 2-digit or 1-digit, 1-digit\n",
    "    elif patterns[2].match(filename) or patterns[3].match(filename):\n",
    "        process_kfp(filename, int(filename[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "57d87ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [05:03<00:00,  3.03s/it]\n"
     ]
    }
   ],
   "source": [
    "for trace_id, trace_list in tqdm(traces.items()):\n",
    "    traces[trace_id] = [extract_features(trace) for trace in trace_list]\n",
    "    \n",
    "with open('../ds19_kfp.npy', 'wb') as f:\n",
    "    pickle.dump(traces, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "33c5fb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SECTION 4\n",
    "# convert our format (from 450k dataset) to the same one as ds-19, then extract k-fp features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35594e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../nonzero_traces.npy', 'rb') as f:\n",
    "    traces = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d29a67e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_format(trace):\n",
    "    return [(abs(packet),np.sign(packet)) for packet in trace]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4670af34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [16:51<00:00, 10.11s/it]\n"
     ]
    }
   ],
   "source": [
    "for trace_id, trace_list in tqdm(traces.items()):\n",
    "    traces[trace_id] = [convert_format(trace) for trace in trace_list]\n",
    "    \n",
    "for trace_id, trace_list in tqdm(traces.items()):\n",
    "    traces[trace_id] = [extract_features(trace) for trace in trace_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96e60385",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../nonzero_kfp.npy', 'wb') as f:\n",
    "    pickle.dump(traces, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0951d7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SECTION 5\n",
    "# save traces with low average distances to file for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3abc61f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [\"num=0\",\"num=1\",\"num=2\",\"num=3\",\"num=4\",\"num=5\"]\n",
    "\n",
    "for name in filenames:\n",
    "    with open('../results/data/X/' + name, 'rb') as f:\n",
    "        X = pickle.load(f)\n",
    "    with open('../results/data/y/' + name, 'rb') as f:\n",
    "        y = pickle.load(f)\n",
    "    \n",
    "    average_distances = [np.mean(X[i:i+100]) for i in range(0,10000,100)]\n",
    "    distance_ids = np.argsort(average_distances)\n",
    "    \n",
    "    with open(\"../results/data/distances/\" + name + \"min=1\", 'wb') as f:\n",
    "        pickle.dump(distance_ids[:50], f)\n",
    "    with open(\"../results/data/distances/\" + name + \"min=0\", 'wb') as f:\n",
    "        pickle.dump(distance_ids[50:], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7dc22792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SECTION 6\n",
    "\n",
    "# convert ds19 to inter-packet timing\n",
    "\n",
    "with open(\"../datasets/ds19.npy\", 'rb') as f:\n",
    "    traces = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ea8e849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "1214\n"
     ]
    }
   ],
   "source": [
    "print(len(traces))\n",
    "print(len(traces[0]))\n",
    "print(len(traces[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2dc6769a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_ipt(trace):\n",
    "    processed_trace = np.zeros(len(trace), dtype=np.float32)\n",
    "    signs = np.sign(trace)\n",
    "    for i, x in enumerate(trace):\n",
    "        distance = abs(x) - abs(trace[i-1])\n",
    "        value = signs[i] * distance\n",
    "        processed_trace[i] = value\n",
    "    \n",
    "    return processed_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00554e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for trace_id, trace_list in traces.items():\n",
    "    traces[trace_id] = [convert_to_ipt(trace) for trace in trace_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c4d80b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../datasets/ds19_ipt.npy\", 'wb') as f:\n",
    "    pickle.dump(traces, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d63e009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "eb11c0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../datasets/ds19.npy\", 'rb') as f:\n",
    "    traces = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0c7e2bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_traces(traces, overlap_factor):\n",
    "    signs = [np.sign(trace) for trace in traces]\n",
    "\n",
    "    overlap_val_1 = abs(traces[0][round(len(traces[0]) * (1-overlap_factor))])\n",
    "    overlap_val_2 = abs(traces[1][round(len(traces[1]) * (1-overlap_factor))])\n",
    "    \n",
    "    traces[1] = [(abs(traces[1][i]) + overlap_val_1) * signs[1][i] for i in range(len(traces[1]))]\n",
    "    traces[2] = [(abs(traces[2][i]) + overlap_val_1 + overlap_val_2) * signs[2][i] for i in range(len(traces[2]))]\n",
    "    \n",
    "    combined = np.concatenate((traces[0], traces[1], traces[2]))\n",
    "    \n",
    "    return sorted(combined, key=abs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
