{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c6f2c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import stumpy\n",
    "import pickle\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "from pipelinetools import *\n",
    "from multiprocessing import Pool\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fd24a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD ORIGINALS OF TRANSFORMER DATASET AND CONVERT TO OUR FORMAT (ONLY NEED TO RUN ONCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f445486c",
   "metadata": {},
   "outputs": [],
   "source": [
    "traces_train = load_traces('transformer/train')\n",
    "traces_test = load_traces('transformer/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f21e659f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_transformer(traces):\n",
    "    trace_ids = list(set(traces['label']))\n",
    "    new_traces = {id: [] for id in trace_ids}\n",
    "    \n",
    "    for i in tqdm(range(len(traces['data']))):\n",
    "        time = traces['time'][i]\n",
    "        direction = traces['data'][i]\n",
    "        label = traces['label'][i]\n",
    "        \n",
    "        new_trace = np.multiply(time, direction).astype('float64')\n",
    "        new_traces[label].append(new_trace)\n",
    "        \n",
    "    return new_traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "56595feb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 8000/8000 [00:00<00:00, 65819.72it/s]\n",
      "100%|███████████████████████████████████| 2000/2000 [00:00<00:00, 116865.53it/s]\n",
      "100%|███████████████████████████████████████████| 51/51 [05:42<00:00,  6.72s/it]\n"
     ]
    }
   ],
   "source": [
    "traces_train = reformat_transformer(traces_train)\n",
    "traces_test = reformat_transformer(traces_test)\n",
    "traces_kfp = process_traces(traces_train, 'kfp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "afb703a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../datasets/transformer_train\", 'wb') as f:\n",
    "    pickle.dump(traces_train, f)\n",
    "\n",
    "with open(\"../datasets/transformer_test\", 'wb') as f:\n",
    "    pickle.dump(traces_test, f)\n",
    "    \n",
    "with open(\"../datasets/transformer_kfp\", 'wb') as f:\n",
    "    pickle.dump(traces_kfp, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15219925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD AND TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6351855",
   "metadata": {},
   "outputs": [],
   "source": [
    "traces_train = load_traces('transformer_train')\n",
    "traces_test = load_traces('transformer_test')\n",
    "traces_kfp = load_traces('transformer_kfp')\n",
    "\n",
    "del traces_train[-1]\n",
    "del traces_test[-1]\n",
    "del traces_kfp[-1]\n",
    "\n",
    "filenames_train = make_name_list({\n",
    "    'data':['transformer_train'],\n",
    "    'centroid_id':list(range(2)),\n",
    "    'distance':['mean']\n",
    "})\n",
    "filenames_test = make_name_list({\n",
    "    'data':['transformer_test'],\n",
    "    'centroid_id':list(range(2)),\n",
    "    'distance':['mean']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27c93f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 50/50 [00:01<00:00, 45.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving shapelets as ../results/shapelets/data=transformer_traincentroid_id=0distance=mean\n",
      "Saving shapelets as ../results/shapelets/data=transformer_traincentroid_id=1distance=mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "shapelets = generate_cluster_shapelets(traces_train, traces_kfp, 2)\n",
    "save_shapelets(shapelets, filenames_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b9bf38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [06:16<00:00, 10.62it/s]\n",
      "100%|██████████| 4000/4000 [06:30<00:00, 10.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving X as ../results/data/X/data=transformer_traincentroid_id=1distance=mean\n",
      "Saving y as ../results/data/y/data=transformer_traincentroid_id=1distance=mean\n"
     ]
    }
   ],
   "source": [
    "parameter_list = [] \n",
    "X, y = traces_to_xy(traces_train)\n",
    "\n",
    "for i in range(len(filenames_train)):\n",
    "    parameter_set = [\n",
    "        filenames_train[i],\n",
    "        X,\n",
    "        y,\n",
    "        shapelets[i],\n",
    "        \"stumpy_mean\"\n",
    "    ]\n",
    "    parameter_list.append(parameter_set)\n",
    "\n",
    "with Pool(2) as p:\n",
    "    p.map(compute_shapelet_distances_mp, parameter_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d0f4135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:33<00:00, 10.70it/s]\n",
      "100%|██████████| 1000/1000 [01:36<00:00, 10.31it/s]\n"
     ]
    }
   ],
   "source": [
    "parameter_list = [] \n",
    "X, y = traces_to_xy(traces_test)\n",
    "\n",
    "for i in range(len(filenames_test)):\n",
    "    parameter_set = [\n",
    "        filenames_test[i],\n",
    "        X,\n",
    "        y,\n",
    "        shapelets[i],\n",
    "        \"stumpy_mean\"\n",
    "    ]\n",
    "    parameter_list.append(parameter_set)\n",
    "    \n",
    "print(len(parameter_list))\n",
    "\n",
    "with Pool(2) as p:\n",
    "    p.map(compute_shapelet_distances_mp, parameter_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e9b757d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_min_train = make_name_list({\n",
    "    'dataset':['transformer'],\n",
    "    'centroid_id':list(range(2)),\n",
    "})\n",
    "filenames_min_test = make_name_list({\n",
    "    'dataset':['transformer_test'],\n",
    "    'centroid_id':list(range(2)),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cafa45ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading X from ../results/data/X/data=transformer_traincentroid_id=0distance=mean\n",
      "Loading X from ../results/data/X/data=transformer_traincentroid_id=1distance=mean\n",
      "Loading y from ../results/data/y/data=transformer_traincentroid_id=0distance=mean\n",
      "Loading X from ../results/data/X/data=transformer_testcentroid_id=0distance=mean\n",
      "Loading X from ../results/data/X/data=transformer_testcentroid_id=1distance=mean\n",
      "Loading y from ../results/data/y/data=transformer_testcentroid_id=0distance=mean\n",
      "Loading X from ../results/data/X/dataset=transformercentroid_id=0\n",
      "Loading X from ../results/data/X/dataset=transformercentroid_id=1\n",
      "Loading y from ../results/data/y/dataset=transformercentroid_id=0\n",
      "Loading X from ../results/data/X/dataset=transformer_testcentroid_id=0\n",
      "Loading X from ../results/data/X/dataset=transformer_testcentroid_id=1\n",
      "Loading y from ../results/data/y/dataset=transformer_testcentroid_id=0\n"
     ]
    }
   ],
   "source": [
    "X_train_mean, y_train = load_xy(filenames_train, True)\n",
    "X_test_mean, y_test = load_xy(filenames_test, True)\n",
    "\n",
    "X_train_min, y_train = load_xy(filenames_min_train, True)\n",
    "X_test_min, y_test = load_xy(filenames_min_test, True)\n",
    "\n",
    "X_train = np.concatenate((X_train_mean, X_train_min), axis=1)\n",
    "X_test = np.concatenate((X_test_mean, X_test_min), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b9f4e3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 200)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ee506384",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "scores = metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bb50357a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.953\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0117508b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) LOAD ORIGINALS OF BIGENOUGH DATASET AND CONVERT TO OUR FORMAT(ONLY RUN ONCE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
