{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "046cafc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import stumpy\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import random\n",
    "import math\n",
    "import pickle\n",
    "from statistics import mean\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cadcd734",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../nonzero_traces.npy', 'rb') as f:\n",
    "    traces = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5512bc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goal: generate shapelets for every combination of traces (no reverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fba8f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapelet_storage = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56ce4958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust the lengths of 2 packet traces so they match\n",
    "# by appending Numpy NaN to the end of the shorter traces\n",
    "def adjust_lengths(long, short):\n",
    "    \n",
    "    # compute the total length, determine how much to append to shorter traces\n",
    "    short_total = sum([len(i) for i in short])\n",
    "    long_total = sum([len(i) for i in long])\n",
    "    extension_size = round((long_total - short_total) / len(long))\n",
    "    \n",
    "    # append NaN entries to the end of each trace in the shorter list\n",
    "    # this way they end up with a similar size\n",
    "    for trace in short:\n",
    "        trace = np.append(trace, [np.nan] * extension_size)\n",
    "    \n",
    "    return long, short\n",
    "\n",
    "def merge_traces(id_1, id_2, num_traces=50):\n",
    "    trace1 = random.sample(traces[id_1], num_traces)\n",
    "    trace2 = random.sample(traces[id_2], num_traces)\n",
    "    \n",
    "    # calculate average packet length\n",
    "    trace1_avg = mean([len(i) for i in trace1])\n",
    "    trace2_avg = mean([len(i) for i in trace2])\n",
    "    \n",
    "    \n",
    "    # if the average length of the traces differes by over 15 % of their average length\n",
    "    # we will append NaN to the ends of packet traces to make them align better\n",
    "    if trace1_avg > trace2_avg:\n",
    "        trace1, trace2 = adjust_lengths(trace1, trace2)\n",
    "    # traces 2 contains longer\n",
    "    else:\n",
    "        trace1, trace2 = adjust_lengths(trace2, trace1)\n",
    "    \n",
    "    trace1_flat = np.asarray([item for row in trace1 for item in row]).astype('float64')\n",
    "    trace2_flat = np.asarray([item for row in trace2 for item in row]).astype('float64')\n",
    "    \n",
    "    \n",
    "    \n",
    "    return trace1_flat, trace2_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f7bf45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_profile(trace1, trace2, m):\n",
    "    \n",
    "    c1_c1 = stumpy.stump(trace1, m)[:, 0].astype(float)\n",
    "    c2_c2 = stumpy.stump(trace2, m)[:, 0].astype(float)\n",
    "    \n",
    "    c1_c1[c1_c1 == np.inf] = np.nan\n",
    "    c2_c2[c2_c2 == np.inf] = np.nan\n",
    "    \n",
    "    \n",
    "    #print(\"self-profiles generated...\")\n",
    "    \n",
    "    c1_c2 = stumpy.stump(trace1, m, trace2, ignore_trivial=False)[:, 0].astype(float)\n",
    "    c2_c1 = stumpy.stump(trace2, m, trace1, ignore_trivial=False)[:, 0].astype(float)\n",
    "    \n",
    "    c1_c2[c1_c2 == np.inf] = np.nan\n",
    "    c2_c1[c2_c1 == np.inf] = np.nan\n",
    "    #print(\"Comparison profiles generated...\")\n",
    "    \n",
    "    return c1_c1, c2_c2, c1_c2, c2_c1\n",
    "\n",
    "def generate_shapelets(diff, trace, m, n):\n",
    "    \n",
    "    shapelet_list = []\n",
    "    # find the maximum difference, append to shapelet list\n",
    "    while(len(shapelet_list) < n):\n",
    "        idx = np.argmax(diff)\n",
    "        shapelet_list.append(trace[idx : idx + m])\n",
    "        \n",
    "        # create an exclusion zone around the index (so shapelets are spread apart)\n",
    "        np.put(diff, list(range( max(idx-n, 0), min(idx + n, len(diff)) )), -1)\n",
    "    \n",
    "    shapelet_list = [x[~np.isnan(x)] for x in shapelet_list]\n",
    "    \n",
    "    return shapelet_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a429d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_to_shapelet(data, shapelets):\n",
    "    \"\"\"\n",
    "    Compute the minimum distance beteen each data sample and a shapelet of interest\n",
    "    \"\"\"\n",
    "    #data = np.asarray(data)\n",
    "    #print(len(data))\n",
    "    \n",
    "    # processed output data\n",
    "    data_out = np.zeros((len(data),len(shapelets)))\n",
    "    \n",
    "    # loop over each sample in the dataset\n",
    "    for i,sample in enumerate(data):\n",
    "        shapelet_score = np.empty(len(shapelets))\n",
    "        # for each shapelet, calculate distance and assign a score\n",
    "        for j,shapelet in enumerate(shapelets):\n",
    "            dist = stumpy.mass(shapelet, sample)\n",
    "            shapelet_score[j] = dist.min()\n",
    "        data_out[i] = shapelet_score\n",
    "    \n",
    "    return data_out\n",
    "\n",
    "def run_classifier(id_1, id_2, c1_shapes, c2_shapes, m, n):\n",
    "    \n",
    "    # generate input data, split into training/testing\n",
    "    X = random.sample(traces[id_1],n)\n",
    "    X.extend(random.sample(traces[id_2],n))\n",
    "    y = [id_1] * n + [id_2] * n\n",
    "    X = [np.asarray(trace).astype('float64') for trace in X]\n",
    "    X = [trace[~np.isnan(trace)] for trace in X]\n",
    "\n",
    "    \n",
    "    removals = [i for i,x in enumerate(X) if len(x) < m]\n",
    "    for idx in removals:\n",
    "        X[idx] = None\n",
    "        y[idx] = None\n",
    "    X = [trace for trace in X if trace is not None]\n",
    "    y = [value for value in y if value is not None]\n",
    "    \n",
    "    \n",
    "    X_c1 = distance_to_shapelet(X, c1_shapes)\n",
    "    X_c2 = distance_to_shapelet(X, c2_shapes)\n",
    "    \n",
    "    X = np.hstack((X_c1, X_c2))\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    \n",
    "    #print(\"Training and testing samples collected ...\")\n",
    "    \n",
    "    clf = GradientBoostingClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    score = metrics.accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "616a9b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_to_shapelet(data, shapelet):\n",
    "    \"\"\"\n",
    "    Compute the minimum distance beteen each data sample and a shapelet of interest\n",
    "    \"\"\"\n",
    "    #data = np.asarray(data)\n",
    "    #print(len(data))\n",
    "    \n",
    "    X = np.empty(len(data))\n",
    "    for i in range(len(data)):\n",
    "        D = stumpy.mass(shapelet, data[i])\n",
    "        X[i] = D.min()\n",
    "\n",
    "    return X.reshape(-1, 1)\n",
    "\n",
    "def run_classifier(id_1, id_2, c1_shapes, c2_shapes, m, n):\n",
    "    sample_size = 250\n",
    "    \n",
    "    # generate input data, split into training/testing\n",
    "    X = random.sample(traces[id_1],n)\n",
    "    X.extend(random.sample(traces[id_2],n))\n",
    "    y = [id_1] * n + [id_2] * n\n",
    "    X = [np.asarray(trace).astype('float64') for trace in X]\n",
    "    X = [trace[~np.isnan(trace)] for trace in X]\n",
    "\n",
    "    \n",
    "    removals = [i for i,x in enumerate(X) if len(x) < m]\n",
    "    for idx in removals:\n",
    "        X[idx] = None\n",
    "        y[idx] = None\n",
    "    X = [trace for trace in X if trace is not None]\n",
    "    y = [value for value in y if value is not None]\n",
    "\n",
    "    X_train_org, X_test_org, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    \n",
    "    #print(\"Training and testing samples collected ...\")\n",
    "    \n",
    "    clf = RandomForestClassifier()\n",
    "    max_accuracy = 0\n",
    "    \n",
    "    for i, (c1_shape, c2_shape) in enumerate(zip(c1_shapes, c2_shapes)):\n",
    "        X_c1 = distance_to_shapelet(X_train_org, c1_shape)\n",
    "        X_c2 = distance_to_shapelet(X_train_org, c2_shape)\n",
    "        X_train = np.concatenate((X_c1, X_c2), axis=1)\n",
    "\n",
    "        X_c1 = distance_to_shapelet(X_test_org, c1_shape)\n",
    "        X_c2 = distance_to_shapelet(X_test_org, c2_shape)\n",
    "        X_test = np.concatenate((X_c1, X_c2), axis=1)\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        \n",
    "        max_accuracy = max(max_accuracy, metrics.accuracy_score(y_test, y_pred))\n",
    "        \n",
    "    return max_accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ae0286e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_shapelets(id_1, id_2, num_traces=20, shapelet_size=500, num_shapelets = 10, sample_size=100):\n",
    "    \n",
    "    # get packet traces and merge\n",
    "    trace1, trace2 = merge_traces(id_1, id_2, num_traces)\n",
    "    \n",
    "    #print(\"Traces Merged...\")\n",
    "    \n",
    "    # compute differences\n",
    "    c1_c1, c2_c2, c1_c2, c2_c1 = generate_profile(trace1, trace2, shapelet_size)\n",
    "    \n",
    "    # find largest value gap between self and other\n",
    "    \n",
    "    diff_c1 = c1_c2 - c1_c1\n",
    "    diff_c2 = c2_c1 - c2_c2\n",
    "    \n",
    "    #print(\"Differences Computed...\")\n",
    "    \n",
    "    # get maximum points (i.e. shapelets)\n",
    "    \n",
    "    c1_shapes = generate_shapelets(diff_c1, trace1, shapelet_size, num_shapelets)\n",
    "    c2_shapes = generate_shapelets(diff_c2, trace2, shapelet_size, num_shapelets)\n",
    "    \n",
    "    #print(\"Shapelets Generated...\")\n",
    "    \n",
    "    final_score = run_classifier(id_1, id_2, c1_shapes, c2_shapes, shapelet_size, sample_size)\n",
    "    \n",
    "    return final_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c23657b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_shapelets(22,88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd842ec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nResults\\n\\n\\n\\n# which classifier is used to predict outcome\\nClassifier: [XGBoost, RandomForest]\\n\\n# pass data for all shapelets into classifier, or just single shapelet and report best score\\nShapelet Choice: [All, Best]\\n\\n# whether incoming (positive), outgoing (negative), or both directions are used\\nPacket Direction: [Positive, Negative, Both]\\n\\n# consider shapelet distance from both packet traces or just one\\nTraces: [Both, One]\\n\\nAccuracy using parameters:\\n(Classifier, shapelet choice, packet direction, traces)\\n\\n(XGBoost, All, Positive, One): 0.86\\n(XGBoost, All, Positive, Both): 0.88\\n(XGBoost, All, Both, Both): 0.88\\n(XGBoost, All, Negative, Both): 0.87\\n\\n(XGBoost, Best, Negative, Both): 0.93\\n(XGBoost, Best, Both, Both): 0.93\\n\\n(RandomForest, Best, Both, Both): \\n\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Results\n",
    "\n",
    "\n",
    "\n",
    "# which classifier is used to predict outcome\n",
    "Classifier: [XGBoost, RandomForest]\n",
    "\n",
    "# pass data for all shapelets into classifier, or just single shapelet and report best score\n",
    "Shapelet Choice: [All, Best]\n",
    "\n",
    "# whether incoming (positive), outgoing (negative), or both directions are used\n",
    "Packet Direction: [Positive, Negative, Both]\n",
    "\n",
    "# consider shapelet distance from both packet traces or just one\n",
    "Traces: [Both, One]\n",
    "\n",
    "Accuracy using parameters:\n",
    "(Classifier, shapelet choice, packet direction, traces)\n",
    "\n",
    "(XGBoost, All, Positive, One): 0.86\n",
    "(XGBoost, All, Positive, Both): 0.88\n",
    "(XGBoost, All, Both, Both): 0.88\n",
    "(XGBoost, All, Negative, Both): 0.87\n",
    "\n",
    "(XGBoost, Best, Negative, Both): 0.93\n",
    "(XGBoost, Best, Both, Both): 0.93\n",
    "\n",
    "(RandomForest, Best, Both, Both): 0.92\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "# work with her\n",
    "# how much can she help\n",
    "# her own research topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f641e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c8fecfb7e5241d0bf059a8ca7b0181c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Average: 1.0\n",
      "Running Average: 0.925\n",
      "Running Average: 0.9166666666666666\n",
      "Running Average: 0.8625\n",
      "Running Average: 0.89\n",
      "Running Average: 0.8916666666666666\n",
      "Running Average: 0.8941558441558441\n",
      "Running Average: 0.8886363636363637\n",
      "Running Average: 0.901010101010101\n",
      "Running Average: 0.9009090909090909\n",
      "Running Average: 0.9099173553719008\n",
      "Running Average: 0.9049242424242424\n",
      "Running Average: 0.9036907536907537\n",
      "Running Average: 0.8998556998556998\n",
      "Running Average: 0.9065319865319865\n",
      "Running Average: 0.9092487373737373\n",
      "Running Average: 0.9057635175282234\n",
      "Running Average: 0.9109988776655443\n",
      "Running Average: 0.9051568314726209\n",
      "Running Average: 0.9098989898989899\n",
      "Running Average: 0.9098605098605098\n",
      "Running Average: 0.9139577594123048\n",
      "Running Average: 0.9176987263943785\n",
      "Running Average: 0.9148779461279462\n",
      "Running Average: 0.9182828282828283\n",
      "Running Average: 0.9214257964257964\n",
      "Running Average: 0.9243359521137299\n",
      "Running Average: 0.9198953823953824\n",
      "Running Average: 0.9192093347265761\n",
      "Running Average: 0.9152356902356902\n",
      "Running Average: 0.916357119582926\n",
      "Running Average: 0.9189709595959596\n",
      "Running Average: 0.9214263850627487\n",
      "Running Average: 0.9193256090314914\n",
      "Running Average: 0.9216305916305916\n",
      "Running Average: 0.9182519640852974\n",
      "Running Average: 0.9191100191100191\n",
      "Running Average: 0.9212387028176502\n",
      "Running Average: 0.9232582232582233\n",
      "Running Average: 0.9226767676767677\n",
      "Running Average: 0.9196846513919684\n",
      "Running Average: 0.9192159692159693\n",
      "Running Average: 0.9199318769086211\n",
      "Running Average: 0.9217516069788797\n",
      "Running Average: 0.9190460157126824\n",
      "Running Average: 0.9208058849363198\n",
      "Running Average: 0.9214270363206534\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for i in tqdm(range(50)):\n",
    "\n",
    "    a = random.randrange(100)\n",
    "    b = random.randrange(100)\n",
    "    \n",
    "    try:\n",
    "        score = score_shapelets(a, b)\n",
    "    except ValueError:\n",
    "        continue\n",
    "        \n",
    "    scores.append(score)\n",
    "    \n",
    "    if(score < 0.7):\n",
    "        print(\"Bad (score=\" + str(score) + \"): \" + \"ID1=\" + str(a) + \" ID2=\" +  str(b))\n",
    "    \n",
    "    print(\"Running Average: \" + str(mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e810c8d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
